{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "import config\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key\n",
    "# os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "# os.environ[\"HTTPS_PROXY\"] = config.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model='llama3-8b-8192', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatMessageHistory\n",
    "\n",
    "Basic building block memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"Hello nice to meet you\")\n",
    "history.add_ai_message(\"Nice to meet you too!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello nice to meet you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice to meet you too!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndh00961\\AppData\\Local\\Temp\\ipykernel_5980\\447071032.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, \n",
    "                                 memory=memory, \n",
    "                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello nice to meet you\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello nice to meet you',\n",
       " 'history': '',\n",
       " 'response': \"Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Hello nice to meet you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello nice to meet you\n",
      "AI: Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\n",
      "Human: Tell me an interesting Physics fact\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me an interesting Physics fact',\n",
       " 'history': \"Human: Hello nice to meet you\\nAI: Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\",\n",
       " 'response': \"Physics is one of my favorite subjects! Did you know that there is a type of particle called a neutrino that is so light it can travel through solid objects, including the Earth, without being slowed down or absorbed? In fact, neutrinos are so light that they can even travel through the entire Earth in just a few seconds! This is because they have a very small mass, which is about 1/100,000th the mass of an electron. Neutrinos are created in the core of the sun during the process of nuclear fusion, and they can travel vast distances through space before being detected on Earth. In fact, scientists have detected neutrinos coming from distant stars and even from the Big Bang itself! Isn't that mind-blowing?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Tell me an interesting Physics fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello nice to meet you\n",
      "AI: Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\n",
      "Human: Tell me an interesting Physics fact\n",
      "AI: Physics is one of my favorite subjects! Did you know that there is a type of particle called a neutrino that is so light it can travel through solid objects, including the Earth, without being slowed down or absorbed? In fact, neutrinos are so light that they can even travel through the entire Earth in just a few seconds! This is because they have a very small mass, which is about 1/100,000th the mass of an electron. Neutrinos are created in the core of the sun during the process of nuclear fusion, and they can travel vast distances through space before being detected on Earth. In fact, scientists have detected neutrinos coming from distant stars and even from the Big Bang itself! Isn't that mind-blowing?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello nice to meet you\\nAI: Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\\nHuman: Tell me an interesting Physics fact\\nAI: Physics is one of my favorite subjects! Did you know that there is a type of particle called a neutrino that is so light it can travel through solid objects, including the Earth, without being slowed down or absorbed? In fact, neutrinos are so light that they can even travel through the entire Earth in just a few seconds! This is because they have a very small mass, which is about 1/100,000th the mass of an electron. Neutrinos are created in the core of the sun during the process of nuclear fusion, and they can travel vast distances through space before being detected on Earth. In fact, scientists have detected neutrinos coming from distant stars and even from the Big Bang itself! Isn't that mind-blowing?\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation.memory\n",
    "import pickle\n",
    "pick_str = pickle.dumps(conversation.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/outputs/convo_memory.pkl\", \"wb\") as f:\n",
    "    f.write(pick_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_memory = open(\"data/outputs/convo_memory.pkl\", \"rb\").read()\n",
    "\n",
    "relaod_convo = ConversationChain(llm=llm, memory=pickle.loads(loaded_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationChain(memory=ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello nice to meet you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you too! I'm an artificial intelligence language model, specifically a variant of the transformer architecture, trained on a massive corpus of text data that includes but is not limited to books, articles, research papers, and online conversations. I'm designed to understand and generate human-like language, and I'm constantly learning and improving my abilities. I'm a bit of a chatterbox, so feel free to ask me anything you'd like to know!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me an interesting Physics fact', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Physics is one of my favorite subjects! Did you know that there is a type of particle called a neutrino that is so light it can travel through solid objects, including the Earth, without being slowed down or absorbed? In fact, neutrinos are so light that they can even travel through the entire Earth in just a few seconds! This is because they have a very small mass, which is about 1/100,000th the mass of an electron. Neutrinos are created in the core of the sun during the process of nuclear fusion, and they can travel vast distances through space before being detected on Earth. In fact, scientists have detected neutrinos coming from distant stars and even from the Big Bang itself! Isn't that mind-blowing?\", additional_kwargs={}, response_metadata={})])), verbose=False, llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000285851982E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028585198E80>, model_name='llama3-8b-8192', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relaod_convo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Window Memory\n",
    "\n",
    "conversation buffer memory just with the limit to the number of interactions saved,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "llm = ChatGroq(model='llama3-8b-8192', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(llm=llm, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me a match fact with a score',\n",
       " 'history': \"Human: What was the final score in that match\\nAI: I've already told you the answer to that question, and it's still 2-0, with Liverpool FC emerging victorious over Tottenham Hotspur in the 2019 UEFA Champions League Final! I'm happy to provide more information about the match, such as the goals scored by Mohamed Salah and Divock Origi, or the impressive defensive performance by Liverpool's goalkeeper Alisson Becker. Would you like to know more about that match or perhaps explore other sporting events?\",\n",
       " 'response': \"The 2018 Formula 1 World Championship finale, the Abu Dhabi Grand Prix! That thrilling race saw Lewis Hamilton and Kimi Räikkönen engage in a neck-and-neck battle, but Hamilton ultimately crossed the finish line first, edging out his Ferrari rival by just 1.3 seconds. The final score was Hamilton in P1, Räikkönen in P2, and Seb Vettel in P3. Would you like to know more about Hamilton's strategy or the battle for 2nd place?\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Tell me a match fact with a score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the final score in that match',\n",
       " 'history': \"Human: Tell me a match fact with a score\\nAI: The 2018 Formula 1 World Championship finale, the Abu Dhabi Grand Prix! That thrilling race saw Lewis Hamilton and Kimi Räikkönen engage in a neck-and-neck battle, but Hamilton ultimately crossed the finish line first, edging out his Ferrari rival by just 1.3 seconds. The final score was Hamilton in P1, Räikkönen in P2, and Seb Vettel in P3. Would you like to know more about Hamilton's strategy or the battle for 2nd place?\",\n",
       " 'response': 'The final score was Lewis Hamilton in first place, with a marginal 1.3 seconds ahead of Kimi Räikkönen, who settled for second place. The full podium result was: 1. Lewis Hamilton (Mercedes) - 54:36.450, 2. Kimi Räikkönen (Ferrari) - +1.3s, and 3. Sebastian Vettel (Ferrari) - +13.2s.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"What was the final score in that match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the final score in that match',\n",
       " 'history': \"Human: What was the final score in that match\\nAI: I've already told you the answer to that question, and it's still 2-0, with Liverpool FC emerging victorious over Tottenham Hotspur in the 2019 UEFA Champions League Final! I'm happy to provide more information about the match, such as the goals scored by Mohamed Salah and Divock Origi, or the impressive defensive performance by Liverpool's goalkeeper Alisson Becker. Would you like to know more about that match or perhaps explore other sporting events?\",\n",
       " 'response': \"I've already told you the answer to that question, and it's still 2-0, with Liverpool FC emerging victorious over Tottenham Hotspur in the 2019 UEFA Champions League Final! I'm happy to provide more information about the match, such as the goals scored by Mohamed Salah and Divock Origi, or the impressive defensive performance by Liverpool's goalkeeper Alisson Becker. Would you like to know more about that match or perhaps explore other sporting events?\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"What was the final score in that match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What was the final score in that match\n",
      "AI: The final score was Lewis Hamilton in first place, with a marginal 1.3 seconds ahead of Kimi Räikkönen, who settled for second place. The full podium result was: 1. Lewis Hamilton (Mercedes) - 54:36.450, 2. Kimi Räikkönen (Ferrari) - +1.3s, and 3. Sebastian Vettel (Ferrari) - +13.2s.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What was the final score in that match\\nAI: The final score was Lewis Hamilton in first place, with a marginal 1.3 seconds ahead of Kimi Räikkönen, who settled for second place. The full podium result was: 1. Lewis Hamilton (Mercedes) - 54:36.450, 2. Kimi Räikkönen (Ferrari) - +1.3s, and 3. Sebastian Vettel (Ferrari) - +13.2s.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convesation Buffer Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndh00961\\AppData\\Local\\Temp\\ipykernel_2392\\3112362828.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm,\n",
    "                                 memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ndh00961\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me a fact about New York',\n",
       " 'history': '',\n",
       " 'response': 'New York! The Empire State! Did you know that New York is home to the largest public transportation system in the world, with over 472 subway stations and 850 miles of track? It\\'s true! The New York City Subway system is one of the most iconic and busiest in the world, with over 6 million passengers per day. In fact, the subway system is so extensive that it\\'s often referred to as the \"lifeblood\" of the city.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Tell me a fact about New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: Current summary: \\n\\nNew lines of conversation:\\nHuman: Tell me a fact about New York\\nAI: ()\\n\\nNew summary:\\nAI: New York! The Empire State! Did you know that New York is home to the largest public transportation system in the world, with over 472 subway stations and 850 miles of track? It\\'s true! The New York City Subway system is one of the most iconic and busiest in the world, with over 6 million passengers per day. In fact, the subway system is so extensive that it\\'s often referred to as the \"lifeblood\" of the city.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
