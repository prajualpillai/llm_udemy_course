{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, getpass\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = 'You are an reciepe assistant that specializes in {diet_pref} dishes that can be prepared in {time} time'\n",
    "sys_msg_prmpt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = '{recipe_req}'\n",
    "hmn_msg_prmpt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['diet_pref', 'time'], ['recipe_req'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_msg_prmpt.input_variables, hmn_msg_prmpt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diet_pref', 'recipe_req', 'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prmpt = ChatPromptTemplate.from_messages([sys_msg_prmpt, hmn_msg_prmpt])\n",
    "chat_prmpt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prmpt.format_prompt(diet_pref='Indian', time='20 min', recipe_req='snack').to_messages()\n",
    "result = llm.invoke(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Prompt and Models\n",
    "\n",
    "Creating a function to generate a hobby itneary for a given budget using llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_idea(hobby, budget):\n",
    "\n",
    "    llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "    system_template = 'Create a travel itenary for {hobby} within the given budget {budget}.'\n",
    "    system_prmpt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    chat_prmpt = ChatPromptTemplate.from_messages([system_prmpt])\n",
    "    prompt = chat_prmpt.format_prompt(hobby=hobby, budget=budget).to_messages()\n",
    "    result = llm.invoke(prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a great adventure you're about to embark on! With a budget of $10,000, you can explore some fantastic fishing destinations around the world. Here's a suggested itinerary for you:\\n\\n**Day 1-5: Galapagos Islands, Ecuador**\\n\\n* Fly from Quito, Ecuador to the Galapagos Islands ( approx. $800 return)\\n* Spend 5 days exploring the unique fishing spots in the islands, targeting species like marlin, sailfish, and tuna\\n* Guided fishing trips with local experts will cost around $200-300 per day\\n* Accommodation: Stay in a comfortable eco-lodge or hotel in Puerto Ayora, Santa Cruz Island (approx. $100-150 per night)\\n\\n**Day 6-12: Costa Rica**\\n\\n* Fly from the Galapagos to San Jose, Costa Rica (approx. $500 return)\\n* Spend 6 days exploring the Pacific coast of Costa Rica, targeting species like tarpon, snook, and roosterfish\\n* Guided fishing trips with local experts will cost around $250-350 per day\\n* Accommodation: Stay in a beachfront hotel or eco-lodge in Tamarindo or Puerto Viejo (approx. $150-250 per night)\\n\\n**Day 13-19: Belize**\\n\\n* Fly from Costa Rica to Belize City, Belize (approx. $400 return)\\n* Spend 6 days exploring the crystal-clear waters of Belize, targeting species like bonefish, permit, and tarpon\\n* Guided fishing trips with local experts will cost around $200-300 per day\\n* Accommodation: Stay in a comfortable hotel or lodge in Placencia or Ambergris Caye (approx. $100-200 per night)\\n\\n**Budget Breakdown:**\\n\\n* Flights: $2,400 (avg. $400 per leg)\\n* Accommodation: $2,500 (avg. $125 per night)\\n* Guided fishing trips: $2,500 (avg. $250 per day)\\n* Food and other expenses: $1,000\\n* Total: $8,400\\n\\n**Remaining Budget:**\\n\\n* You'll have $600 left over for any additional expenses, such as souvenirs, tips, or additional activities like snorkeling or wildlife tours.\\n\\nThis itinerary should provide a great balance of fishing adventure and relaxation, while staying within your budget. However, feel free to adjust the itinerary to fit your preferences and interests. Happy fishing!\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_idea('fishing', '$10000').to_json()[\"kwargs\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Prompt Template\n",
    "\n",
    "Give an example of input output pairs for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Bot legal --> Simple Terms\n",
    "\n",
    "system_template = 'You are a helpful legal assistant that translates complex legal terms into plain and simple terms.'\n",
    "sys_msg_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "\n",
    "# Input Human\n",
    "legal_text = \"\"\"This contract, effective upon execution, requires both parties to adhere to its terms. \n",
    "                Any changes must be agreed upon in writing. Breach of any provision entitles the other \n",
    "                party to pursue legal remedies. All disputes arising from this agreement will be resolved \n",
    "                in the designated jurisdiction's courts.\"\"\"\n",
    "example_input_1 = HumanMessagePromptTemplate.from_template(legal_text)\n",
    "# AI Output\n",
    "output = \"\"\"Contract effective upon signing; disputes resolved in specified court.\"\"\"\n",
    "\n",
    "example_output_1 = AIMessagePromptTemplate.from_template(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{legal_text}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prmpt = ChatPromptTemplate.from_messages([sys_msg_prompt, human_prompt, example_input_1, example_output_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_legal_text = \"\"\"This agreement binds both parties to its terms upon signing. \n",
    "                        Any changes must be in writing and signed by both parties. \n",
    "                        If either party fails to follow the terms, the other may seek legal remedies. \n",
    "                        Any disputes will be resolved in the court of the specified jurisdiction.\"\"\"\n",
    "request = chat_prmpt.format_prompt(legal_text=example_legal_text).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 188, 'total_tokens': 189, 'completion_time': 0.001333333, 'prompt_time': 0.044276491, 'queue_time': -9223372036.899054, 'total_time': 0.045609824}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'stop', 'logprobs': None}, id='run-01fef76d-2cc9-48be-9355-5eac6394b9e3-0', usage_metadata={'input_tokens': 188, 'output_tokens': 1, 'total_tokens': 189})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "result = llm.invoke(request)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few shot prompt not working with groq, maybe due to token limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, CommaSeparatedListOutputParser\n",
    "\n",
    "# Step 1: Import Parser and make an instance\n",
    "output_parser = JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breeds': 340,\n",
       " 'communication': {'body_language': True,\n",
       "  'barking': True,\n",
       "  'whining': True,\n",
       "  'vocalizations': True},\n",
       " 'senses': {'smell': '700 times stronger than humans',\n",
       "  'hearing': '4 times more sensitive than humans',\n",
       "  'vision': 'limited color spectrum compared to humans'},\n",
       " 'lifespan': {'average': '10-13 years', 'varies_by_breed': True},\n",
       " 'training': {'capable_of_learning': True,\n",
       "  'responds_to_positive_reinforcement': True}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_template = \"{request}\\n{format_instructions}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "model_request = chat_prompt.format_prompt(request='Give me five facts about dogs',\n",
    "                                          format_instructions=output_parser.get_format_instructions()).to_messages()\n",
    "output_parser.parse(llm.invoke(model_request).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do when the parser is not good enough for formating outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0827-02-04T18:01:46.873161Z, 0892-12-02T12:27:08.938545Z, 0408-06-21T08:30:56.457048Z\\n\\nReturn ONLY this string, no other words!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser, OutputFixingParser\n",
    "op_parse = DatetimeOutputParser()\n",
    "op_parse.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Provide the date required by the user in the format {system_format_instruction}\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text = '{request}\\n{format_instructions}'\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(template_text)\n",
    "chat_prmpt = ChatPromptTemplate.from_messages([human_prompt]) # system_prompt, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_request = chat_prmpt.format_prompt(request=\"What date was the 13th Ammendement ratified in te US?\",\n",
    "                                        format_instructions = op_parse.get_format_instructions(),\n",
    "                                        system_format_instruction =  op_parse.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
    "result = llm.invoke(model_request).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'December 18, 1865'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 12, 18, 0, 0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OutputParser doesn't always fix the problem\n",
    "new_parser = OutputFixingParser.from_llm(parser=op_parse, llm=llm)\n",
    "#op_parse.parse(result)\n",
    "new_parser.parse(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pydantic Library\n",
    "Is used for type validation\n",
    "\n",
    "- List doesn't work in the parser and groq output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scientist(BaseModel):\n",
    "\n",
    "    name: str = Field(description='Name of a Scientist')\n",
    "    discoversies: tuple = Field(description='Python tuple of discoveries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Scientist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Name of a Scientist\", \"title\": \"Name\", \"type\": \"string\"}, \"discoversies\": {\"description\": \"Python tuple of discoveries\", \"items\": {}, \"title\": \"Discoversies\", \"type\": \"array\"}}, \"required\": [\"name\", \"discoversies\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\"You should only return the output in the requested format and nothing else.\")\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"{request}\\n Output in {format} format\")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "request = chat_prompt.format_prompt(request=\"Tell me about a famous Scientist\",\n",
    "                                    format = parser.get_format_instructions()).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Marie Curie\", \"discoversies\": [\"Radioactivity\", \"Elements Polonium and Radium\"]}'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(request)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scientist(name='Marie Curie', discoversies=('Radioactivity', 'Elements Polonium and Radium'))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Scientist"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parser.parse(result.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization: Saving and Loading Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Tell me a fact about {planet}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"planet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.save(\"saved_prompts/my_prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['planet'], input_types={}, partial_variables={}, template='Tell me a fact about {planet}')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "loaded_prompt = load_prompt(\"saved_prompts/my_prompt.json\")\n",
    "loaded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2: Build a historical quiz bot\n",
    "\n",
    "Build a quiz bot which does the following:\n",
    "\n",
    "- Class should be present\n",
    "- Write a class which has the date as the correct answer\n",
    "    - First method which generates a history question on the given topic\n",
    "    - Second method, send the generated question to the AI chatbot which returns the datetime object\n",
    "    - Get the user answer: yyyy-mm-dd\n",
    "    - Find how off the user's answer was from the ai answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "import config\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
    "        self.system_prompt = SystemMessagePromptTemplate.from_template(\"You are a datetime bot which returns only the asked date in the {ques_format} format, nothing else\")\n",
    "        self.op_parser = DatetimeOutputParser()\n",
    "\n",
    "\n",
    "    def gen_ques(self, topic:str):\n",
    "        \"\"\"Generate a question for the given topic\"\"\"\n",
    "\n",
    "        # human_template = \"On which date did {topic} end?\"\n",
    "        system_template = \"\"\"You generate a single question inquiring about a date related to {topic}. You only return the quiz question. \n",
    "                             Do not ask about multiple dates.\"\"\"\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(template=system_template)\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(template=\"Generate a question about {topic}.\")\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "        request = chat_prompt.format_prompt(topic=topic).to_messages()\n",
    "        question = self.llm.invoke(request)\n",
    "        print(\"Question: \",question.content)\n",
    "        return question.content\n",
    "    \n",
    "    def get_ai_ans(self, question):\n",
    "        \n",
    "        chat_prompt =  ChatPromptTemplate.from_messages([self.system_prompt, question])\n",
    "        request = chat_prompt.format_prompt(ques_format=self.op_parser.get_format_instructions()).to_messages()\n",
    "        model_ans = self.llm.invoke(request)\n",
    "        parsed_ans = self.op_parser.parse(model_ans.content)\n",
    "\n",
    "        return parsed_ans\n",
    "    \n",
    "    def get_user_ans(self):\n",
    "\n",
    "        date = input(\"Enter date in dd-mm-yyyy format: \")\n",
    "        date = pd.to_datetime(date, format=\"%d-%m-%Y\")\n",
    "        print(\"User date: \", date)\n",
    "        return date\n",
    "    \n",
    "    def check_ans(self, ai_ans, user_ans):\n",
    "\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(\"\"\"You have to tell the difference between two dates in days, months and years, with sign values date_1 - date_2. \n",
    "                                                                  Only give the final difference in a single line, no explanation required. The answer should be similar to:\n",
    "                                                                  The difference in dates is x years, y months and z dates, where x, y, z are the differences with the proper sign values. \n",
    "                                                                  \"\"\")\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(\"Find  {date_1} - {date_2}\")\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "        request = chat_prompt.format_prompt(date_1=ai_ans, date_2=user_ans).to_messages()\n",
    "        ans = self.llm.invoke(request).content\n",
    "        print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  On what date did the United States drop an atomic bomb on the Japanese city of Hiroshima?\n",
      "User date:  2023-12-04 00:00:00\n",
      "AI ans:  1945-08-06 06:15:27\n",
      "The difference in dates is 78 years, 4 months and 28 days.\n"
     ]
    }
   ],
   "source": [
    "obj = Solution()\n",
    "request = obj.gen_ques(\"World War 2\")\n",
    "ai_ans = obj.get_ai_ans(request)\n",
    "user_date = obj.get_user_ans()\n",
    "print(\"AI ans: \", ai_ans)\n",
    "obj.check_ans(ai_ans, user_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Connections\n",
    "\n",
    "- Load Documents: pdf, html, etc\n",
    "- Convert to vector embeddings\n",
    "- Query data from those documents\n",
    "\n",
    "install pypdf and beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "import config\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key\n",
    "os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "os.environ[\"HTTPS_PROXY\"] = config.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader, BSHTMLLoader, PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(\"data/inputs/test_data.csv\") # does lazy loading\n",
    "data = loader.load()\n",
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Name: Jane Doe\n",
      "Point1: 15/20\n",
      "Point2: 30/50\n",
      "Point3: 18/20\n",
      "Extra: Had extraodinary participation in MUN.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BSHTMLLoader(\"data/inputs/test_html.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/inputs/test_html.html', 'title': ''}, page_content='Heading 1')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heading 1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRAJUAL PILLAI\\nML Engineer\\n@prajualpillai05@gmail.com ♂phone+91-9415008195 /githubhttps:/ /github.com/prajualpillai\\n/linkedinhttps:/ /www.linkedin.com/in/prajual-pillai-b4945112b/\\nEXPERIENCE\\nML Engineer II\\nNissan Digital LLP\\nὌ5September 2023 – Ongoing ♂¶ap-¶arkerTrivandrum, India\\n•Developing an in-house MMM model with mape of 22%\\n•Developed a forecasting model to predict the powetrain mix till 2030\\n•Part of the team which was runner up in Inter-Nissan AWS Gameday\\n•Developed a used car price forecasting poc which was one of the 8\\nshortlisted ideas(out of 200+ ) for Nissan Ideathon/Hackathon.\\n•Held a session on the usage of DVC for model & data versioning\\nML Engineer\\nSearce Inc.\\nὌ5July 2021 – September 2023 ♂¶ap-¶arkerPune, India\\nClient: Futureproof July, 2023 – July, 2023\\n•Developed a CI/CD pipeline for model training pipeline using DVC\\n•Set up the architecture for integrating DVC with VertexAI\\n•Developed the model and data versioning module for the pipeline\\nClient: Searce March, 2023 – April, 2023\\n•Developed a Named Entity Recognition model from scratch using spacy3.1\\n•Extracted 9entities from driving licenses with an accuracy of 93.1%\\n•Included an image extraction model using yolov8 to extract the images\\n•Extracted photo and signature with accuracies of 95.7% and78.3%\\n•Built a FastApi endpoint to orchestrate the process through an api call\\nClient: Healthians Septermber, 2022 – February, 2023\\n•Developed collaborative ﬁlter based recommendation system using\\nTensorﬂow-recommenders to recommend medical tests to clients\\n•Trained, tuned & deployed an 80% accurate model in AWS Sagemaker\\n•Deployment of the same also done using AWS Lamda &AWS ECR\\n•Setup AWS API Gateway as the trigger for the Lambda deployment\\n•Performed exploratory analysis of over 6TB of data in order to identify\\nand aggregate parameters for the model\\nClient: Flipkart January – September, 2022\\n•Worked with Google team to migrate 3PB of on-prem data to GCS\\n•Mapped bucket & object policy from AWS toGCS at scale\\n•Deployed the multi-threaded python code on GKE for data migration\\n•Performed data veriﬁcation & analysis of the copied objects at scale\\nProduct: Recognic August – December, 2021\\n•Used DML to build models to extract text from custom documents\\n•Utilised Vision API to extract text from generic documents\\n•Increased performance of existing code by 50% by optimising the en-\\ncoding used for the vision callsEDUCATION\\nM.Tech, IIT Bombay\\nManufacturing 2021\\nPerformance- 8.79\\nB.Tech, Kerala University\\nMechanical 2017\\nPerformance- 7.45\\nIntermediate, St. Fidelis College\\nI.C.S.E 2013\\nPerformance- 81.3\\nACHIEVEMENTS\\nSecured 99.22 percentile in Graduate Ap-\\ntitude Test in Engineering(GATE-19) among\\n1.67 lakh candidates\\nCERTIFICATES\\nGCP: Professional ML Engineer, Associate\\nCloud Engineer\\nAWS: AWS Certiﬁed Cloud Practitioner\\nCoursera: Applied Data Science Capstone,\\nNeural Networks and Deep Learning\\nTECHNICAL SKILLS\\nProgramming: Python , Java, SQL\\nAWS: S3,Sagemaker , ECR, Lambda , Glue\\nGCP: GCS, BigQuery, Pub/Sub , Spanner,\\nCloud Functions, Dataﬂow, VertexAI, Cloud\\nScheduler, Cloud Composer ,DocAI\\nML Frameworks and Libraries: Tensorﬂow ,\\nPyTorch, Darts, Spacy, BERT\\nEXTRA CURRICULAR\\n•Represented Mechanical Dept. in the PG inter-\\ndepartment volleyball tournament at IITB.\\nBLOGS\\n•Custom Recommendation System\\n•Performing NER using spacy3.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"data/inputs/test_pdf.pdf\")\n",
    "data = loader.load()\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrations\n",
    "\n",
    "- Document loaders which are integrated to some specific 3rd party, such as google cloud, wiki, aws, etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import HNLoader\n",
    "os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "os.environ[\"HTTPS_PROXY\"] = config.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = HNLoader(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Main_Page (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;31mSSLError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Main_Page (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\langchain_community\\document_loaders\\hn.py:25\u001b[0m, in \u001b[0;36mHNLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get important HN webpage information.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    HN webpage components are:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m        - rank of the post\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     soup_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweb_path:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_comments(soup_info)\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\langchain_community\\document_loaders\\web_base.py:324\u001b[0m, in \u001b[0;36mWebBaseLoader.scrape\u001b[1;34m(self, parser)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parser\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\langchain_community\\document_loaders\\web_base.py:308\u001b[0m, in \u001b[0;36mWebBaseLoader._scrape\u001b[1;34m(self, url, parser, bs_kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m         parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parser\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_parser(parser)\n\u001b[1;32m--> 308\u001b[0m html_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequests_kwargs)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_for_status:\n\u001b[0;32m    310\u001b[0m     html_doc\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\requests\\adapters.py:698\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='en.wikipedia.org', port=443): Max retries exceeded with url: /wiki/Main_Page (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)')))"
     ]
    }
   ],
   "source": [
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loader Exercise\n",
    "\n",
    "Using wikipedia integration, make a function that accepts a famous historical figure name and a question about them, and then uses a ChatModel to answer questions with the additional context.\n",
    "\n",
    "- Make a call to wiki to get the doc\n",
    "- Insert additional context to the chat model and answer the user's question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "import config\n",
    "import os\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key\n",
    "# os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "# os.environ[\"HTTPS_PROXY\"] = config.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = WikipediaLoader(query=\"HUNTER X HUNTER\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nicolas Kim Coppola (born January 7, 1964), known professionally as Nicolas Cage, is an American actor and film producer. He is the recipient of various accolades, including an Academy Award, a Screen Actors Guild Award, and a Golden Globe Award as well as nominations for two BAFTA Awards. Known for his versatility as an actor, his participation in various film genres has gained him a cult following.\n",
      "Born into the Coppola family, Cage began his career in films such as Fast Times at Ridgemont High (1982) and Valley Girl (1983), as well as various films by his uncle Francis Ford Coppola such as Rumble Fish (1983), The Cotton Club (1984), and Peggy Sue Got Married (1986). He received critical success for his roles in Moonstruck and  Raising Arizona (both 1987), before earning an Academy Award for Best Actor for the dramatic film Leaving Las Vegas (1995). He was Oscar-nominated for playing twins Charlie and Donald Kaufman in the comedy-drama film Adaptation (2002).\n",
      "Cage established himself in mainstream action films, such as The Rock (1996), Con Air (1997), Face/Off (1997), Gone in 60 Seconds (2000), the National Treasure film series (2004–2007), the Ghost Rider film series (2007–2011), and Kick-Ass (2010). He also took on dramatic roles in City of Angels (1998), Bringing Out the Dead (1999),  The Family Man (2000), Matchstick Men (2003), and The Wicker Man (2006). He has voiced characters in The Croods film series (2013–2020) and in Spider-Man: Into the Spider-Verse (2018). He earned renewed critical recognition for his starring roles in Mandy (2018), Pig (2021), The Unbearable Weight of Massive Talent (2022), Dream Scenario (2023) and Longlegs (2024).\n",
      "Cage owns the production company Saturn Films and has produced films such as Shadow of the Vampire (2000) and The Life of David Gale (2003), and has directed Sonny (2002). For his contributions to the film industry, he was inducted into the Hollywood Walk of Fame in 1998. He was ranked No. 40 in Empire magazine's The Top 100 Movie Stars of All Time list in 2007 and was placed No. 37 in Premiere's 100 Most Powerful People in Hollywood in 2008.\n",
      "\n",
      "\n",
      "== Early life and family ==\n",
      "Cage was born in Long Beach, California, to August Coppola, a professor of literature, and Joy Vogelsang, a dancer and choreographer. He was raised in a Catholic family. His father was of Italian descent and his mother was of mainly German and Polish descent with some English and Scottish ancestry on her father's side. His paternal grandparents were composer Carmine Coppola and actress Italia Pennino, and his paternal great-grandparents were immigrants from Bernalda, Basilicata. Through his father, he is a nephew of both director Francis Ford Coppola and actress Talia Shire, and a cousin of directors Roman Coppola and Sofia Coppola, film producer Gian-Carlo Coppola, and actors Robert and Jason Schwartzman.\n",
      "Cage is the youngest of three sons. His two brothers are New York radio personality Marc \"The Cope\" Coppola and director Christopher Coppola. He attended Beverly Hills High School, which is known for its many alumni who became entertainers. He aspired to act from an early age and also attended UCLA School of Theater, Film and Television. His first non-cinematic acting experience was in a school production of Golden Boy. He said he started acting because he \"wanted to be James Dean. I saw him in Rebel Without a Cause, East of Eden. Nothing affected me—no rock song, no classical music—the way Dean affected me in Eden. It blew my mind. I was like, 'That's what I want to do'.\"\n",
      "At age 15, he tried to convince his uncle, Francis Ford Coppola, to give him a screen test, telling him \"I'll show you acting.\" His outburst was met with \"silence in the car.\" By this stage of his career, Coppola had already directed Marlon Brando, Al Pacino, Gene Hackman and Robert De Niro. Although early in his career Cage appeared in some of his uncle's films, he changed his name to Nicolas Cage to avoid the appearance of nepotism as Coppol Nicolas Cage is an American actor whose career began with a role in the 1981 television pilot The Best of Times. The following year, Cage made his feature film acting debut with a minor role in Fast Times at Ridgemont High, the second and last time he went by his birth name Nicolas Coppola, which he changed professionally to avoid allegations of nepotism due to his connection to the Coppola family. In 1983, Cage starred in the teen romantic comedy Valley Girl alongside Deborah Foreman and had a supporting role in his uncle Francis Ford Coppola's Rumble Fish.\n",
      "In 1984, Cage portrayed a fictionalized version of hitman Mad Dog Coll in Coppola's The Cotton Club and appeared in Birdy, a feature the National Board of Review listed among the top ten films of that year. He starred in Coppola's Peggy Sue Got Married in 1986 before leading the 1987 crime comedy Raising Arizona, written and directed by the Coen brothers. In 1988, he earned a Golden Globe nomination for Best Actor – Motion Picture Musical or Comedy for his role as the romantic lead in Moonstruck. In 1989, he appeared in the black comedy film Vampire's Kiss, a box-office bomb that later gained a cult following for his \"chaotic\" performance. In 1990, he led the David Lynch film Wild at Heart.\n",
      "In 1992, Cage earned his second Golden Globe nomination for the romantic comedy Honeymoon in Vegas. Three years later, he starred as a suicidal alcoholic in the critically acclaimed Leaving Las Vegas, for which he received a BAFTA Award nomination for Best Actor in a Leading Role, and earned the Golden Globe for Best Actor – Motion Picture Drama and the Academy Award for Best Actor. In 2002, he made his directorial debut with Sonny and portrayed filmmaker Charlie Kaufman in Adaptation, another critically acclaimed film that earned him his most recent Best Actor nominations from the Academy Awards, BAFTA, and Golden Globes.\n",
      "In the 1990s, Cage's career rocketed as a leading man; films of his that made over $100 million in theaters included The Rock (1996), Con Air (1997), Face/Off (1997), City of Angels (1998), Snake Eyes (1998), Gone in 60 Seconds (2000), The Family Man (2000), National Treasure and its sequel (2004; 2007), World Trade Center (2006), Ghost Rider and its sequel (2007; 2011), Knowing (2009), and The Sorcerer's Apprentice (2010). In the 2010s, Cage found himself \"taking roles left and right\" after a series of box-office disappointments and to pay off his debts to the IRS, placing him in numerous films, many going direct-to-video. His participation in various genres during this time increased his popularity and gained him a cult following. Luke Buckmaster, for The Guardian, wrote, \"In Cage's hands, cartoonish moments are imbued with real emotion and real emotions become cartoons. He is erratic and unpredictable; he is captivating and he is capricious. He is a performer.\" Cage's highest-grossing movie is the 2013 animated film The Croods. His additional voice roles include Superman in Teen Titans Go! To the Movies and Spider-Man Noir in Spider-Man: Into the Spider-Verse (both 2018). Recent films of his that earned critical acclaim include Mandy (2018), Color Out of Space (2019), Pig (2021), The Unbearable Weight of Massive Talent (2022), Dream Scenario (2023), and Longlegs (2024).\n",
      "\n",
      "\n",
      "== Film ==\n",
      "\n",
      "\n",
      "== Television ==\n",
      "\n",
      "\n",
      "== Video game ==\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Nicolas Cage at IMDb\n",
      "Nicolas Cage at Rotten Tomatoes\n",
      "Ans:  Nicolas Cage was born on January 7, 1964.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
    "\n",
    "def get_wiki_content(topic):\n",
    "    content = WikipediaLoader(query=topic, load_max_docs=2).load()\n",
    "    ans = ''\n",
    "    for page in content:\n",
    "        ans += \" \" + page.page_content\n",
    "    return ans\n",
    "\n",
    "def get_answer(content, question):\n",
    "\n",
    "    system_template = \"Given the content {content}, fetch the answer to the question asked by the user.\"\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "    human_template = \"{question}\"\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate([system_prompt, human_prompt])\n",
    "    request = chat_prompt.format_prompt(content = content, question = question).to_messages()\n",
    "    ans = llm.invoke(request).content\n",
    "\n",
    "    return ans\n",
    "\n",
    "content = get_wiki_content(\"Nicholas Cage\")\n",
    "print(content)\n",
    "ans = get_answer(content, \"When was he born?\")\n",
    "print(\"Ans: \", ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Transformers\n",
    "\n",
    "The length of string fed from a document might be too large to feed into a model. Transformers splits these strings into chunks which will later serve useful for uembeddings, which can be then looked up using a dustance similarity later on.\n",
    "\n",
    "Splitting can be of two types:\n",
    "- Splitting on a specific character\n",
    "- Splitting based on token coubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/fdr_speech.txt') as file:\n",
    "    speech_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3415"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech_text.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splitter = CharacterTextSplitter(separator = \"\\n\\n\", chunk_size=1000)\n",
    "texts = test_splitter.create_documents([speech_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='IN FULFILLING my duty to report upon the State of the Union, I am proud to say to you that the spirit of the American people was never higher than it is todayâ€”the Union was never more closely knit togetherâ€”this country was never more deeply determined to face the solemn tasks before it.\\n\\nThe response of the American people has been instantaneous, and it will be sustained until our security is assured.\\n\\nExactly one year ago today I said to this Congress: \"When the dictators. . . are ready to make war upon us, they will not wait for an act of war on our part. . . . Theyâ€”not weâ€”will choose the time and the place and the method of their attack.\"\\n\\nWe now know their choice of the time: a peaceful Sunday morningâ€” December 7, 1941.\\n\\nWe know their choice of the place: an American outpost in the Pacific.\\n\\nWe know their choice of the method: the method of Hitler himself.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --proxy=10.203.32.190:8080 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "texts = test_splitter.split_text(speech_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeddings\n",
    "\n",
    "- Choose your embedding model carefully, embedding using model A might not be same as that created by model B.\n",
    "- If a change is to be made all the historical data will have to be changed to the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence_transformers\n",
    "# !pip install --proxy=10.203.32.190:8080 --upgrade --quiet  langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "import config\n",
    "import os\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key\n",
    "# os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "# os.environ[\"HTTPS_PROXY\"] = config.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndh00961\\AppData\\Local\\Temp\\ipykernel_7116\\619240441.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "c:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\ndh00961\\Desktop\\personal_data\\personal_code\\langchain_personal_exp\\lang_env\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ndh00961\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"this is a normal text string that I want to embedd as a vector\"\n",
    "embedded_text = embeddings.embed_query(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/inputs/test_data.csv', 'row': 0}, page_content='ï»¿Name: Jane Doe\\nPoint1: 15/20\\nPoint2: 30/50\\nPoint3: 18/20\\nExtra: Had extraodinary participation in MUN.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(\"data/inputs/test_data.csv\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.03533982113003731,\n",
       "  0.01674029417335987,\n",
       "  -0.009271835908293724,\n",
       "  0.019534962251782417,\n",
       "  -0.005103622563183308,\n",
       "  0.020624931901693344,\n",
       "  -0.0357869528234005,\n",
       "  0.02432936243712902,\n",
       "  -0.0183588694781065,\n",
       "  0.021252483129501343,\n",
       "  0.050105124711990356,\n",
       "  -0.005557351280003786,\n",
       "  0.04851042106747627,\n",
       "  0.05048724263906479,\n",
       "  -0.034426599740982056,\n",
       "  0.023692147806286812,\n",
       "  0.010839156806468964,\n",
       "  -0.0028201015666127205,\n",
       "  0.05511929839849472,\n",
       "  -0.03273586928844452,\n",
       "  -0.03653135150671005,\n",
       "  0.03010758012533188,\n",
       "  -0.046307001262903214,\n",
       "  0.006526881828904152,\n",
       "  -0.015589394606649876,\n",
       "  0.028450822457671165,\n",
       "  0.04805194213986397,\n",
       "  0.015371604822576046,\n",
       "  0.014143470674753189,\n",
       "  -0.02525527961552143,\n",
       "  0.007123374845832586,\n",
       "  0.017143912613391876,\n",
       "  -0.030109021812677383,\n",
       "  -0.07371345907449722,\n",
       "  1.7974085722016753e-06,\n",
       "  -0.047407034784555435,\n",
       "  0.0011947546154260635,\n",
       "  0.011869785375893116,\n",
       "  -0.046314746141433716,\n",
       "  -0.02209063619375229,\n",
       "  -0.055808067321777344,\n",
       "  0.0028645230922847986,\n",
       "  0.011434421874582767,\n",
       "  0.0017061609541997313,\n",
       "  -0.011239399202167988,\n",
       "  0.013511099852621555,\n",
       "  0.008997628465294838,\n",
       "  0.02448500692844391,\n",
       "  0.03984810411930084,\n",
       "  0.011201808229088783,\n",
       "  -0.005640033166855574,\n",
       "  -0.002976134652271867,\n",
       "  0.015334074385464191,\n",
       "  -0.06035055220127106,\n",
       "  0.1248362809419632,\n",
       "  -0.005000067874789238,\n",
       "  -0.014118202030658722,\n",
       "  0.02590310014784336,\n",
       "  9.498697181697935e-06,\n",
       "  -0.01985573023557663,\n",
       "  0.023808469995856285,\n",
       "  -0.020900126546621323,\n",
       "  -0.015392870642244816,\n",
       "  0.028468120843172073,\n",
       "  -0.021982671692967415,\n",
       "  0.018437761813402176,\n",
       "  0.03371060639619827,\n",
       "  -0.0018271331209689379,\n",
       "  0.03410807624459267,\n",
       "  0.000720668351277709,\n",
       "  0.04948451742529869,\n",
       "  0.031211338937282562,\n",
       "  -0.013351419940590858,\n",
       "  0.021895844489336014,\n",
       "  -0.013539758510887623,\n",
       "  -0.021275974810123444,\n",
       "  -0.036566730588674545,\n",
       "  -0.03726908192038536,\n",
       "  0.018812570720911026,\n",
       "  -0.04484843462705612,\n",
       "  -0.0017685235943645239,\n",
       "  0.07544804364442825,\n",
       "  0.0031665824353694916,\n",
       "  0.0027896875981241465,\n",
       "  -0.045999687165021896,\n",
       "  -0.005706702824681997,\n",
       "  -0.01009905431419611,\n",
       "  -0.0009000211139209569,\n",
       "  -0.017826654016971588,\n",
       "  -0.030044646933674812,\n",
       "  -0.03188806399703026,\n",
       "  -0.015718506649136543,\n",
       "  0.02334580011665821,\n",
       "  -0.007314556278288364,\n",
       "  -0.01809333637356758,\n",
       "  -0.05793420970439911,\n",
       "  0.038374919444322586,\n",
       "  -0.02846461907029152,\n",
       "  0.04375642538070679,\n",
       "  -0.015109440311789513,\n",
       "  0.037524040788412094,\n",
       "  0.007733400911092758,\n",
       "  -0.0008707576780579984,\n",
       "  0.023144541308283806,\n",
       "  0.020562278106808662,\n",
       "  0.01604756899178028,\n",
       "  0.04768950864672661,\n",
       "  0.027653470635414124,\n",
       "  -0.06940040737390518,\n",
       "  -0.009391737170517445,\n",
       "  -0.00933591928333044,\n",
       "  -9.810774645302445e-05,\n",
       "  -0.024760562926530838,\n",
       "  0.03179379180073738,\n",
       "  0.08872723579406738,\n",
       "  0.040612079203128815,\n",
       "  -0.0732392817735672,\n",
       "  -0.04321546480059624,\n",
       "  -0.015075050294399261,\n",
       "  -0.032727889716625214,\n",
       "  0.0609731562435627,\n",
       "  -0.01662425883114338,\n",
       "  0.0182955302298069,\n",
       "  0.010530087165534496,\n",
       "  -0.051225680857896805,\n",
       "  -0.011959702707827091,\n",
       "  -0.0816870927810669,\n",
       "  0.007573062554001808,\n",
       "  0.04810083284974098,\n",
       "  -0.0174929890781641,\n",
       "  -0.004057250916957855,\n",
       "  -0.009796512313187122,\n",
       "  0.04423539713025093,\n",
       "  -0.03608112037181854,\n",
       "  0.03234735131263733,\n",
       "  0.053977128118276596,\n",
       "  0.041948456317186356,\n",
       "  0.01429497729986906,\n",
       "  0.050425250083208084,\n",
       "  -0.0014409745344892144,\n",
       "  0.054765939712524414,\n",
       "  -0.044247105717659,\n",
       "  -0.0098321083933115,\n",
       "  0.0002780902141239494,\n",
       "  0.03210799768567085,\n",
       "  0.008451886475086212,\n",
       "  0.030666671693325043,\n",
       "  0.02492336928844452,\n",
       "  0.008719999343156815,\n",
       "  -0.010991224087774754,\n",
       "  -0.028143446892499924,\n",
       "  -0.013849754817783833,\n",
       "  0.044058460742235184,\n",
       "  -0.0077017731964588165,\n",
       "  0.0546431764960289,\n",
       "  0.018492089584469795,\n",
       "  -0.01748582348227501,\n",
       "  -0.05433797091245651,\n",
       "  0.03723803535103798,\n",
       "  0.03425878286361694,\n",
       "  0.014045123010873795,\n",
       "  -0.02538195066154003,\n",
       "  0.004469495266675949,\n",
       "  0.014375090599060059,\n",
       "  0.0035620841663330793,\n",
       "  -0.035269368439912796,\n",
       "  0.08589670807123184,\n",
       "  0.005311859305948019,\n",
       "  -0.04553331434726715,\n",
       "  0.018376771360635757,\n",
       "  -0.010113147087395191,\n",
       "  0.021595144644379616,\n",
       "  0.009018126875162125,\n",
       "  0.028008781373500824,\n",
       "  -0.013767133466899395,\n",
       "  0.11633431166410446,\n",
       "  0.04298735409975052,\n",
       "  -0.08717367798089981,\n",
       "  0.006904643960297108,\n",
       "  -0.07671438157558441,\n",
       "  0.00822092592716217,\n",
       "  -0.11525595188140869,\n",
       "  -0.023789159953594208,\n",
       "  0.003558242227882147,\n",
       "  -0.01223299652338028,\n",
       "  0.00735956896096468,\n",
       "  -0.03036525286734104,\n",
       "  0.01569262519478798,\n",
       "  -0.03626734018325806,\n",
       "  -0.022792108356952667,\n",
       "  0.01802332140505314,\n",
       "  0.017437664791941643,\n",
       "  -0.04906067997217178,\n",
       "  0.05059986189007759,\n",
       "  -0.027117425575852394,\n",
       "  0.032117877155542374,\n",
       "  0.01063797902315855,\n",
       "  -0.04309812933206558,\n",
       "  -0.04235498607158661,\n",
       "  -0.04260493442416191,\n",
       "  0.0014874577755108476,\n",
       "  -0.044490404427051544,\n",
       "  -0.006203373894095421,\n",
       "  0.03271597623825073,\n",
       "  0.029731398448348045,\n",
       "  -0.026682207360863686,\n",
       "  0.021432116627693176,\n",
       "  -0.04876888543367386,\n",
       "  -0.014310267753899097,\n",
       "  -0.03492759168148041,\n",
       "  0.06277234107255936,\n",
       "  0.012459478341042995,\n",
       "  0.062024034559726715,\n",
       "  -0.0028920911718159914,\n",
       "  0.022881170734763145,\n",
       "  0.05714540556073189,\n",
       "  0.01333440002053976,\n",
       "  0.03825046122074127,\n",
       "  -0.01419894490391016,\n",
       "  -0.03613517805933952,\n",
       "  0.012221922166645527,\n",
       "  -0.04184958338737488,\n",
       "  -0.047109831124544144,\n",
       "  0.007817464880645275,\n",
       "  -0.016995785757899284,\n",
       "  0.008550760336220264,\n",
       "  0.02493925765156746,\n",
       "  -0.049139391630887985,\n",
       "  0.027269693091511726,\n",
       "  0.04027050361037254,\n",
       "  0.053176149725914,\n",
       "  0.043958719819784164,\n",
       "  0.032922886312007904,\n",
       "  -0.01106137316673994,\n",
       "  0.06377183645963669,\n",
       "  -0.00876693520694971,\n",
       "  0.028939643874764442,\n",
       "  -0.009299304336309433,\n",
       "  -0.03247552365064621,\n",
       "  -0.004420217592269182,\n",
       "  0.001088094781152904,\n",
       "  -0.00854440126568079,\n",
       "  0.018828226253390312,\n",
       "  -0.026418199762701988,\n",
       "  -0.012687967158854008,\n",
       "  -0.00975867174565792,\n",
       "  -0.045115165412425995,\n",
       "  -0.013915174640715122,\n",
       "  0.022888489067554474,\n",
       "  0.05559621378779411,\n",
       "  0.015755880624055862,\n",
       "  0.03184761106967926,\n",
       "  0.010723456740379333,\n",
       "  -0.027345724403858185,\n",
       "  0.026287147775292397,\n",
       "  -0.014962250366806984,\n",
       "  -0.11496812850236893,\n",
       "  -0.008962702937424183,\n",
       "  -0.08059339225292206,\n",
       "  0.02482323907315731,\n",
       "  -0.017329012975096703,\n",
       "  -0.013405571691691875,\n",
       "  0.00766794616356492,\n",
       "  -0.017226172611117363,\n",
       "  0.017814315855503082,\n",
       "  -0.004814727697521448,\n",
       "  -0.03687489032745361,\n",
       "  0.01204127911478281,\n",
       "  -0.006632206030189991,\n",
       "  -0.017637383192777634,\n",
       "  0.007432191167026758,\n",
       "  -0.003306732978671789,\n",
       "  0.07508257031440735,\n",
       "  -0.0020160251297056675,\n",
       "  -0.005492620635777712,\n",
       "  -0.03302406147122383,\n",
       "  -0.023533882573246956,\n",
       "  0.039726510643959045,\n",
       "  0.020672090351581573,\n",
       "  0.031142177060246468,\n",
       "  0.036861177533864975,\n",
       "  0.05079135298728943,\n",
       "  -0.009714280255138874,\n",
       "  -0.019168920814990997,\n",
       "  -0.01649368181824684,\n",
       "  -0.012776012532413006,\n",
       "  0.009205386973917484,\n",
       "  -0.05670160427689552,\n",
       "  0.0007371905958279967,\n",
       "  -0.00800019409507513,\n",
       "  -0.01343494188040495,\n",
       "  -0.0172578115016222,\n",
       "  -0.00016995785699691623,\n",
       "  -0.006546087097376585,\n",
       "  0.007936151698231697,\n",
       "  -0.030474117025732994,\n",
       "  -0.011056394316256046,\n",
       "  0.01283482275903225,\n",
       "  0.011086766608059406,\n",
       "  0.061139386147260666,\n",
       "  -0.020661771297454834,\n",
       "  -0.006713865790516138,\n",
       "  -0.03740987554192543,\n",
       "  -0.004847217816859484,\n",
       "  0.028377532958984375,\n",
       "  0.07009800523519516,\n",
       "  0.012804966419935226,\n",
       "  -0.008284198120236397,\n",
       "  -0.05492505803704262,\n",
       "  -0.09249774366617203,\n",
       "  0.0474923737347126,\n",
       "  -0.005389958154410124,\n",
       "  0.02465175651013851,\n",
       "  0.02999827452003956,\n",
       "  0.01971866562962532,\n",
       "  -0.058771900832653046,\n",
       "  -0.03315357118844986,\n",
       "  0.038379695266485214,\n",
       "  -0.021172212436795235,\n",
       "  0.03158973902463913,\n",
       "  -0.00880134291946888,\n",
       "  0.06205412372946739,\n",
       "  -0.013952071778476238,\n",
       "  0.010013068094849586,\n",
       "  -0.011026266030967236,\n",
       "  -0.011986889876425266,\n",
       "  -0.05331231653690338,\n",
       "  0.05657470226287842,\n",
       "  0.08188200742006302,\n",
       "  0.007568355184048414,\n",
       "  0.01959468610584736,\n",
       "  -0.05985122546553612,\n",
       "  -0.05328486114740372,\n",
       "  0.01415642723441124,\n",
       "  0.010910584591329098,\n",
       "  -0.028072519227862358,\n",
       "  -0.03204219043254852,\n",
       "  -0.03828378766775131,\n",
       "  0.060423195362091064,\n",
       "  -0.030936166644096375,\n",
       "  -0.00432971678674221,\n",
       "  0.011927090585231781,\n",
       "  -0.01811855286359787,\n",
       "  -0.021660216152668,\n",
       "  0.05923963338136673,\n",
       "  0.030031980946660042,\n",
       "  -0.10041839629411697,\n",
       "  0.0435258150100708,\n",
       "  -0.016229670494794846,\n",
       "  -0.028657153248786926,\n",
       "  -0.04541159048676491,\n",
       "  0.049939826130867004,\n",
       "  -0.04138784110546112,\n",
       "  -0.014913211576640606,\n",
       "  -0.0427735410630703,\n",
       "  0.016866380348801613,\n",
       "  0.05221937224268913,\n",
       "  0.06683015078306198,\n",
       "  0.019298430532217026,\n",
       "  -0.06283247470855713,\n",
       "  -0.04250968620181084,\n",
       "  -0.025163117796182632,\n",
       "  -0.0014365483075380325,\n",
       "  0.03861498087644577,\n",
       "  0.06617633253335953,\n",
       "  -0.004973020404577255,\n",
       "  0.03712933138012886,\n",
       "  -0.09672998636960983,\n",
       "  0.001981015782803297,\n",
       "  0.01583120785653591,\n",
       "  0.025448380038142204,\n",
       "  -0.06394064426422119,\n",
       "  0.006587021052837372,\n",
       "  0.0494689904153347,\n",
       "  -0.005975211039185524,\n",
       "  -0.021781345829367638,\n",
       "  -0.006592279765754938,\n",
       "  -0.003675854066386819,\n",
       "  -0.008896132931113243,\n",
       "  0.013227229006588459,\n",
       "  0.01449654158204794,\n",
       "  -0.005542913917452097,\n",
       "  0.07056667655706406,\n",
       "  -0.021896248683333397,\n",
       "  -0.0228346548974514,\n",
       "  -0.01715843193233013,\n",
       "  -0.0033277631737291813,\n",
       "  -0.035102732479572296,\n",
       "  -0.02489154040813446,\n",
       "  0.023271596059203148,\n",
       "  -0.0029224175959825516,\n",
       "  -0.06655099987983704,\n",
       "  -0.027499623596668243,\n",
       "  -0.007158906664699316,\n",
       "  -0.033452898263931274,\n",
       "  0.03358764573931694,\n",
       "  -0.05110892653465271,\n",
       "  0.007979840971529484,\n",
       "  0.032395798712968826,\n",
       "  0.010442719794809818,\n",
       "  -0.0576619915664196,\n",
       "  0.05434670299291611,\n",
       "  -0.06305286288261414,\n",
       "  0.08895010501146317,\n",
       "  -0.03837151825428009,\n",
       "  0.010642710141837597,\n",
       "  0.04767591506242752,\n",
       "  0.009730491787195206,\n",
       "  -0.0921817272901535,\n",
       "  -0.058391962200403214,\n",
       "  0.06835908442735672,\n",
       "  -0.04709118604660034,\n",
       "  -0.013089374639093876,\n",
       "  -0.010761232115328312,\n",
       "  0.024618573486804962,\n",
       "  -0.06789201498031616,\n",
       "  -0.013677436858415604,\n",
       "  -0.04328325390815735,\n",
       "  0.04688398912549019,\n",
       "  -0.01827271655201912,\n",
       "  0.009055315516889095,\n",
       "  -0.00854000635445118,\n",
       "  0.05313164368271828,\n",
       "  -0.0014403016539290547,\n",
       "  0.05542187765240669,\n",
       "  -0.03222627937793732,\n",
       "  0.03174152970314026,\n",
       "  0.0008773315348662436,\n",
       "  -0.002959399251267314,\n",
       "  -0.026215318590402603,\n",
       "  0.02478843554854393,\n",
       "  0.058694735169410706,\n",
       "  0.0013212644262239337,\n",
       "  0.045055147260427475,\n",
       "  -0.060833465307950974,\n",
       "  0.04879242926836014,\n",
       "  0.008255740627646446,\n",
       "  0.034022748470306396,\n",
       "  0.00018202712817583233,\n",
       "  0.02427087165415287,\n",
       "  -0.059129372239112854,\n",
       "  0.019044727087020874,\n",
       "  0.0665544643998146,\n",
       "  0.029148316010832787,\n",
       "  0.01837371103465557,\n",
       "  -0.038433462381362915,\n",
       "  0.022405249997973442,\n",
       "  0.020990947261452675,\n",
       "  0.044392265379428864,\n",
       "  -0.01939144916832447,\n",
       "  0.028907863423228264,\n",
       "  0.019995084032416344,\n",
       "  -0.03882351145148277,\n",
       "  -0.0540258064866066,\n",
       "  0.08383703976869583,\n",
       "  -0.06804842501878738,\n",
       "  -0.04661254212260246,\n",
       "  -0.07258787751197815,\n",
       "  -0.002730909502133727,\n",
       "  -0.0006552086560986936,\n",
       "  0.0756058618426323,\n",
       "  0.04619571939110756,\n",
       "  -0.052528440952301025,\n",
       "  -0.0457187183201313,\n",
       "  -0.002340987790375948,\n",
       "  -0.0593748465180397,\n",
       "  -0.046574000269174576,\n",
       "  -0.05878499150276184,\n",
       "  -0.042264554649591446,\n",
       "  -0.04481041431427002,\n",
       "  0.0061456006951630116,\n",
       "  -0.028750363737344742,\n",
       "  -0.045015446841716766,\n",
       "  -0.008049567230045795,\n",
       "  0.036605704575777054,\n",
       "  0.001142066321335733,\n",
       "  -0.0008529411861672997,\n",
       "  -0.026602385565638542,\n",
       "  -0.017370695248246193,\n",
       "  -0.00556311197578907,\n",
       "  0.0964071974158287,\n",
       "  0.05759452283382416,\n",
       "  -0.03602365404367447,\n",
       "  -0.061128880828619,\n",
       "  -0.03201767057180405,\n",
       "  -0.006097570061683655,\n",
       "  -0.05832156166434288,\n",
       "  -0.010507690720260143,\n",
       "  -0.002107698004692793,\n",
       "  -0.03539789095520973,\n",
       "  0.03340331092476845,\n",
       "  -0.029414581134915352,\n",
       "  -0.02354215644299984,\n",
       "  -0.06663747876882553,\n",
       "  -0.007788644637912512,\n",
       "  0.002774457912892103,\n",
       "  -0.01009342446923256,\n",
       "  0.001271597109735012,\n",
       "  0.03329135477542877,\n",
       "  0.05630246177315712,\n",
       "  -0.011803293600678444,\n",
       "  -0.014209196902811527,\n",
       "  0.0029287992510944605,\n",
       "  -0.01485355943441391,\n",
       "  0.04503639042377472,\n",
       "  0.015146824531257153,\n",
       "  -0.0773390606045723,\n",
       "  0.041649896651506424,\n",
       "  -0.050425343215465546,\n",
       "  0.0021981769241392612,\n",
       "  -0.049841903150081635,\n",
       "  0.03893524408340454,\n",
       "  -0.03856419026851654,\n",
       "  0.014429046772420406,\n",
       "  -0.000844330177642405,\n",
       "  0.021438872441649437,\n",
       "  -0.028975263237953186,\n",
       "  0.04552115499973297,\n",
       "  0.010693824850022793,\n",
       "  0.04113195091485977,\n",
       "  0.032156236469745636,\n",
       "  -0.04280892014503479,\n",
       "  0.034421853721141815,\n",
       "  0.0014382293447852135,\n",
       "  -0.00036617135629057884,\n",
       "  0.04497521370649338,\n",
       "  0.04383247345685959,\n",
       "  -0.0049505410715937614,\n",
       "  0.010872666724026203,\n",
       "  0.023880507797002792,\n",
       "  -0.0436825230717659,\n",
       "  0.0028001635801047087,\n",
       "  -0.028989391401410103,\n",
       "  0.06105251982808113,\n",
       "  -0.013621787540614605,\n",
       "  0.01904340088367462,\n",
       "  0.013859527185559273,\n",
       "  0.014421951957046986,\n",
       "  -0.03479335457086563,\n",
       "  -0.02568914368748665,\n",
       "  0.0030569429509341717,\n",
       "  -0.013380455784499645,\n",
       "  0.024112975224852562,\n",
       "  0.06261434406042099,\n",
       "  0.04370780289173126,\n",
       "  0.04764121025800705,\n",
       "  -0.061711449176073074,\n",
       "  -0.001066631986759603,\n",
       "  -0.049434103071689606,\n",
       "  0.008219338022172451,\n",
       "  -0.023417899385094643,\n",
       "  -0.007132404949516058,\n",
       "  0.03461502864956856,\n",
       "  -0.011854950338602066,\n",
       "  0.06214623153209686,\n",
       "  -5.2162007131342214e-33,\n",
       "  -0.02117246575653553,\n",
       "  -0.02140120230615139,\n",
       "  0.048126284033060074,\n",
       "  -0.003309624968096614,\n",
       "  -0.06039615720510483,\n",
       "  -0.032023169100284576,\n",
       "  -4.691342473961413e-05,\n",
       "  -0.039011500775814056,\n",
       "  -0.04162031412124634,\n",
       "  -0.020824257284402847,\n",
       "  0.007122496142983437,\n",
       "  0.014399433508515358,\n",
       "  0.02751847542822361,\n",
       "  0.0016370596131309867,\n",
       "  0.007875860668718815,\n",
       "  -0.0066853854805231094,\n",
       "  -0.00829330738633871,\n",
       "  0.027784397825598717,\n",
       "  -0.017723150551319122,\n",
       "  -0.06279874593019485,\n",
       "  -0.05410080775618553,\n",
       "  0.010447301901876926,\n",
       "  0.009787274524569511,\n",
       "  0.012475868687033653,\n",
       "  0.04767287150025368,\n",
       "  -0.0255489069968462,\n",
       "  -0.02777068130671978,\n",
       "  0.0023146916646510363,\n",
       "  -0.035380952060222626,\n",
       "  0.0020158477127552032,\n",
       "  0.021558698266744614,\n",
       "  0.0034236921928822994,\n",
       "  0.018164895474910736,\n",
       "  0.04709087312221527,\n",
       "  0.032847851514816284,\n",
       "  -0.05033775046467781,\n",
       "  -0.06990976631641388,\n",
       "  -0.061798837035894394,\n",
       "  -0.013410533778369427,\n",
       "  -0.024191468954086304,\n",
       "  -0.0338907465338707,\n",
       "  -0.04581093788146973,\n",
       "  -0.0172495748847723,\n",
       "  -0.020273327827453613,\n",
       "  -0.002787271747365594,\n",
       "  -0.04927719756960869,\n",
       "  0.012121258303523064,\n",
       "  0.004502562340348959,\n",
       "  0.03447072580456734,\n",
       "  0.05487045645713806,\n",
       "  -0.005615931935608387,\n",
       "  0.0009102440089918673,\n",
       "  -0.0130528025329113,\n",
       "  0.0399177148938179,\n",
       "  -0.04887951537966728,\n",
       "  0.03020390309393406,\n",
       "  0.012438970617949963,\n",
       "  -0.06559967249631882,\n",
       "  -0.0047255149111151695,\n",
       "  0.026471400633454323,\n",
       "  -0.04641343653202057,\n",
       "  0.021312447264790535,\n",
       "  -0.012229090556502342,\n",
       "  0.017843693494796753,\n",
       "  -0.03456784039735794,\n",
       "  0.00015842691936995834,\n",
       "  0.06213603913784027,\n",
       "  0.04033472016453743,\n",
       "  0.04064498469233513,\n",
       "  0.037603285163640976,\n",
       "  0.012768439948558807,\n",
       "  -0.009751936420798302,\n",
       "  0.031051523983478546,\n",
       "  0.023500066250562668,\n",
       "  -0.035454414784908295,\n",
       "  -0.0138405067846179,\n",
       "  -0.06195949390530586,\n",
       "  0.0046787625178694725,\n",
       "  0.030902890488505363,\n",
       "  0.022031035274267197,\n",
       "  -0.03825940936803818,\n",
       "  0.013688274659216404,\n",
       "  -0.02507679909467697,\n",
       "  -0.0045317900367081165,\n",
       "  -0.02090359479188919,\n",
       "  -0.06604205816984177,\n",
       "  -0.017512042075395584,\n",
       "  -0.009676092304289341,\n",
       "  0.030618906021118164,\n",
       "  -0.009048854000866413,\n",
       "  0.02404860593378544,\n",
       "  0.023612570017576218,\n",
       "  -0.01213868148624897,\n",
       "  -0.0062869153916835785,\n",
       "  -0.034537918865680695,\n",
       "  0.007032135967165232,\n",
       "  0.02898043766617775,\n",
       "  0.014077415689826012,\n",
       "  -0.028377113863825798,\n",
       "  0.0310963224619627,\n",
       "  0.017027536407113075,\n",
       "  0.03862983360886574,\n",
       "  0.030582673847675323,\n",
       "  -0.011571950279176235,\n",
       "  0.018103735521435738,\n",
       "  0.02067648246884346,\n",
       "  -0.011990108527243137,\n",
       "  -0.02694813348352909,\n",
       "  -0.0356772243976593,\n",
       "  -0.03391117975115776,\n",
       "  0.009978115558624268,\n",
       "  -0.01775795966386795,\n",
       "  0.015280192717909813,\n",
       "  -0.006944453809410334,\n",
       "  0.0014283356722444296,\n",
       "  -0.012002026662230492,\n",
       "  0.0438610203564167,\n",
       "  -0.024665065109729767,\n",
       "  -0.018300171941518784,\n",
       "  0.0023826437536627054,\n",
       "  -0.02803186886012554,\n",
       "  -0.052037663757801056,\n",
       "  0.03927018865942955,\n",
       "  -0.008781020529568195,\n",
       "  -0.026929328218102455,\n",
       "  0.000733551278244704,\n",
       "  0.041922859847545624,\n",
       "  0.01718241535127163,\n",
       "  0.0031451601535081863,\n",
       "  0.031494639813899994,\n",
       "  0.02205534651875496,\n",
       "  0.009062434546649456,\n",
       "  2.450568956646748e-07,\n",
       "  0.0070961154997348785,\n",
       "  0.004458438139408827,\n",
       "  -0.014411254785954952,\n",
       "  -0.03275550901889801,\n",
       "  -0.021233219653367996,\n",
       "  -0.06096870079636574,\n",
       "  -0.025175660848617554,\n",
       "  0.01552138663828373,\n",
       "  0.07245120406150818,\n",
       "  0.08749275654554367,\n",
       "  0.002751604886725545,\n",
       "  -0.009857785888016224,\n",
       "  -0.020440969616174698,\n",
       "  0.02300809696316719,\n",
       "  -0.01919369213283062,\n",
       "  -0.03705702722072601,\n",
       "  0.07572991400957108,\n",
       "  0.031207818537950516,\n",
       "  0.010782781057059765,\n",
       "  0.013833912089467049,\n",
       "  0.06819835305213928,\n",
       "  0.0478936992585659,\n",
       "  0.0348239429295063,\n",
       "  0.019158951938152313,\n",
       "  -0.003947166260331869,\n",
       "  -0.0239097997546196,\n",
       "  -0.05461058393120766,\n",
       "  -0.017843177542090416,\n",
       "  -0.11274923384189606,\n",
       "  0.027720091864466667,\n",
       "  0.0802122950553894,\n",
       "  -0.06354615837335587,\n",
       "  0.03476124256849289,\n",
       "  0.0487341433763504,\n",
       "  -0.014449134469032288,\n",
       "  -0.016155526041984558,\n",
       "  0.09925656765699387,\n",
       "  0.027430985122919083,\n",
       "  -0.0015709480503574014,\n",
       "  0.006477104965597391,\n",
       "  -0.04711798578500748,\n",
       "  0.003442256012931466,\n",
       "  0.02457459457218647,\n",
       "  0.026526743546128273,\n",
       "  0.036098506301641464,\n",
       "  0.04501592367887497,\n",
       "  -0.043368153274059296,\n",
       "  -0.007428968790918589,\n",
       "  -0.031167343258857727,\n",
       "  -0.01671096868813038,\n",
       "  0.04305313900113106,\n",
       "  0.01891389675438404,\n",
       "  -0.04905799403786659,\n",
       "  -0.010872590355575085,\n",
       "  0.0750274807214737,\n",
       "  0.04221681132912636,\n",
       "  -0.026054905727505684,\n",
       "  0.02013218402862549,\n",
       "  0.02290874719619751,\n",
       "  0.01018473133444786,\n",
       "  -0.028196875005960464,\n",
       "  -0.09724502265453339,\n",
       "  0.05386459827423096,\n",
       "  0.03172339126467705,\n",
       "  0.08059347420930862,\n",
       "  -0.0325053445994854,\n",
       "  -0.027571439743041992,\n",
       "  1.9201350097852964e-34,\n",
       "  -0.01323262695223093,\n",
       "  9.015419345814735e-05,\n",
       "  0.027584491297602654,\n",
       "  -0.020582735538482666,\n",
       "  0.05126623064279556,\n",
       "  -0.019304275512695312,\n",
       "  0.004332751967012882,\n",
       "  0.020426973700523376,\n",
       "  0.021535245701670647,\n",
       "  -0.005700733978301287,\n",
       "  -0.05460197478532791]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_docs = embeddings.embed_documents([text.page_content for text in data])\n",
    "embeded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store\n",
    "\n",
    "- Store embeddings to a permanent space\n",
    "- We will require the vector and the text that it was embeded from\n",
    "- VS should be able to 'quiered'\n",
    "\n",
    "Notes:\n",
    "- The embeddings are identified in the vector db using uuids\n",
    "- So if the same uuid is passed to merge into an existing db, it'll throw an error\n",
    "- But if you recode your embeddings, i.e create new embeddings of the same text, you'll create new uuids for the same embeddings\n",
    "- This will cause multiple embeddings of the same text to be present in the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --proxy=10.203.32.190:8080 faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW\n",
    "\n",
    "- Load a document\n",
    "- Split it into chunks\n",
    "- Use the embedding model to convert the chunks into vectors/embeddings\n",
    "- Save the vectors to vector store\n",
    "- 'query' to similarity search the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the document\n",
    "doc = TextLoader('data/inputs/fdr_speech.txt').load()\n",
    "\n",
    "# Splitting the document into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "chunked_text = text_splitter.split_documents(doc)\n",
    "\n",
    "# Convert text to vector embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Save the vector chunks to vector_store\n",
    "library = FAISS.from_documents(chunked_text, embedding=embeddings)\n",
    "library.save_local(\"./vector_db/course_test/fdr_speech\")\n",
    "\n",
    "# Query similarity search the vector store\n",
    "loaded_lib = FAISS.load_local(\"./vector_db/course_test/fdr_speech\", \n",
    "                              embeddings=embeddings,\n",
    "                              allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of victory?\"\n",
    "ans = loaded_lib.similarity_search(query)\n",
    "print(ans[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 686, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# Loading saved db\n",
    "loaded_lib = FAISS.load_local(\"./vector_db/course_test/fdr_speech\", \n",
    "                              embeddings=embeddings,\n",
    "                              allow_dangerous_deserialization=True)\n",
    "\n",
    "l_doc = TextLoader(\"./data/inputs/lincon_speech.txt\").load()\n",
    "l_docs = text_splitter.split_documents(l_doc)\n",
    "\n",
    "new_db_text = FAISS.from_documents(l_docs, embedding=embeddings)\n",
    "\n",
    "# merging new db with old db\n",
    "loaded_lib.merge_from(new_db_text)\n",
    "\n",
    "# Saving updated dbh\n",
    "loaded_lib.save_local(\"./vector_db/course_test/fdr_speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 30 14\n"
     ]
    }
   ],
   "source": [
    "loaded_lib = FAISS.load_local(\"./vector_db/course_test/fdr_speech\", \n",
    "                              embeddings=embeddings,\n",
    "                              allow_dangerous_deserialization=True)\n",
    "print(len(loaded_lib.docstore._dict), len(new_db_text.docstore._dict), len(library.docstore._dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/inputs/lincon_speech.txt'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_doc = loaded_lib.similarity_search('salvery')\n",
    "sim_doc[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store Retrievers\n",
    "\n",
    "- Sometimes vector stores have to be passed as retriever objects\n",
    "- This can be achieved using the as_retrievers() method\n",
    "- The documents can be fetched using the .invoke method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = loaded_lib.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content=\"We must guard against complacency. We must not underrate the enemy. He is powerful and cunningâ€”and cruel and ruthless. He will stop at nothing that gives him a chance to kill and to destroy. He has trained his people to believe that their highest perfection is achieved by waging war. For many years he has prepared for this very conflict- planning, and plotting, and training, arming, and fighting. We have already tasted defeat. We may suffer further setbacks. We must face the fact of a hard war, a long war, a bloody war, a costly war.\\n\\nWe must, on the other hand, guard against defeatism. That has been one of the chief weapons of Hitler's propaganda machineâ€”used time and again with deadly results. It will not be used successfully on the American people.\\n\\nWe must guard against divisions among ourselves and among all the other United Nations. We must be particularly vigilant against racial discrimination in any of its ugly forms. Hitler will try again to breed mistrust and suspicion between one individual and another, one group and another, one race and another, one Government and another. He will try to use the same technique of falsehood and rumor-mongering with which he divided France from Britain. He is trying to do this with us even now. But he will find a unity of will and purpose against him, which will persevere until the destruction of all his black designs upon the freedom and safety of the people of the world.\\n\\nWe cannot wage this war in a defensive spirit. As our power and our resources are fully mobilized, we shall carry the attack against the enemyâ€”we shall hit him and hit him again wherever and whenever we can reach him.\\n\\nWe must keep him far from our shores, for we intend to bring this battle to him on his own home grounds.\\n\\nAmerican armed forces must be used at any place in all the world where it seems advisable to engage the forces of the enemy. In some cases these operations will be defensive, in order to protect key positions. In other cases, these operations will be offensive, in order to strike at the common enemy, with a view to his complete encirclement and eventual total defeat.\\n\\nAmerican armed forces will operate at many points in the Far East.\\n\\nAmerican armed forces will be on all the oceans- helping to guard the essential communications which are vital to the United Nations.\"),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content='IN FULFILLING my duty to report upon the State of the Union, I am proud to say to you that the spirit of the American people was never higher than it is todayâ€”the Union was never more closely knit togetherâ€”this country was never more deeply determined to face the solemn tasks before it.\\n\\nThe response of the American people has been instantaneous, and it will be sustained until our security is assured.\\n\\nExactly one year ago today I said to this Congress: \"When the dictators. . . are ready to make war upon us, they will not wait for an act of war on our part. . . . Theyâ€”not weâ€”will choose the time and the place and the method of their attack.\"\\n\\nWe now know their choice of the time: a peaceful Sunday morningâ€” December 7, 1941.\\n\\nWe know their choice of the place: an American outpost in the Pacific.\\n\\nWe know their choice of the method: the method of Hitler himself.\\n\\nJapan\\'s scheme of conquest goes back half a century. It was not merely a policy of seeking living room: it was a plan which included the subjugation of all the peoples in the Far East and in the islands of the Pacific, and the domination of that ocean by Japanese military and naval control of the western coasts of North, Central, and South America.\\n\\nThe development of this ambitious conspiracy was marked by the war against China in 1894; the subsequent occupation of Korea; the war against Russia in 1904; the illegal fortification of the mandated Pacific islands following 1920; the seizure of Manchuria in 1931; and the invasion of China in 1937.\\n\\nA similar policy of criminal conquest was adopted by Italy. The Fascists first revealed their imperial designs in Libya and Tripoli. In 1935 they seized Abyssinia. Their goal was the domination of all North Africa, Egypt, parts of France, and the entire Mediterranean world.\\n\\nBut the dreams of empire of the Japanese and Fascist leaders were modest in comparison with the gargantuan aspirations of Hitler and his Nazis. Even before they came to power in 1933, their plans for that conquest had been drawn. Those plans provided for ultimate domination, not of any one section of the world, but of the whole earth and all the oceans on it.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content='War costs money. So far, we have hardly even begun to pay for it. We have devoted only 15 percent of our national income to national defense. As will appear in my Budget Message tomorrow, [See APP Note.] our war program for the coming fiscal year will cost 56 billion dollars or, in other words, more than half of the estimated annual national income. That means taxes and bonds and bonds and taxes. It means cutting luxuries and other non-essentials. In a word, it means an \"all-out\" war by individual effort and family effort in a united country.\\n\\nOnly this all-out scale of production will hasten the ultimate all-out victory. Speed will count. Lost ground can always be regained- lost time never. Speed will save lives; speed will save this Nation which is in peril; speed will save our freedom and our civilizationâ€”and slowness has never been an American characteristic.\\n\\nAs the United States goes into its full stride, we must always be on guard against misconceptions which will arise, some of them naturally, or which will be planted among us by our enemies.\\n\\nWe must guard against complacency. We must not underrate the enemy. He is powerful and cunningâ€”and cruel and ruthless. He will stop at nothing that gives him a chance to kill and to destroy. He has trained his people to believe that their highest perfection is achieved by waging war. For many years he has prepared for this very conflict- planning, and plotting, and training, arming, and fighting. We have already tasted defeat. We may suffer further setbacks. We must face the fact of a hard war, a long war, a bloody war, a costly war.\\n\\nWe must, on the other hand, guard against defeatism. That has been one of the chief weapons of Hitler\\'s propaganda machineâ€”used time and again with deadly results. It will not be used successfully on the American people.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content=\"The development of this ambitious conspiracy was marked by the war against China in 1894; the subsequent occupation of Korea; the war against Russia in 1904; the illegal fortification of the mandated Pacific islands following 1920; the seizure of Manchuria in 1931; and the invasion of China in 1937.\\n\\nA similar policy of criminal conquest was adopted by Italy. The Fascists first revealed their imperial designs in Libya and Tripoli. In 1935 they seized Abyssinia. Their goal was the domination of all North Africa, Egypt, parts of France, and the entire Mediterranean world.\\n\\nBut the dreams of empire of the Japanese and Fascist leaders were modest in comparison with the gargantuan aspirations of Hitler and his Nazis. Even before they came to power in 1933, their plans for that conquest had been drawn. Those plans provided for ultimate domination, not of any one section of the world, but of the whole earth and all the oceans on it.\\n\\nWhen Hitler organized his Berlin-Rome-Tokyo alliance, all these plans of conquest became a single plan. Under this, in addition to her own schemes of conquest, Japan's role was obviously to cut off our supply of weapons of war to Britain, and Russia and China- weapons which increasingly were speeding the day of Hitler's doom. The act of Japan at Pearl Harbor was intended to stun usâ€”to terrify us to such an extent that we would divert our industrial and military strength to the Pacific area, or even to our own continental defense.\\n\\nThe plan has failed in its purpose. We have not been stunned. We have not been terrified or confused. This very reassembling of the Seventy-seventh Congress today is proof of that; for the mood of quiet, grim resolution which here prevails bodes ill for those who conspired and collaborated to murder world peace.\\n\\nThat mood is stronger than any mere desire for revenge. It expresses the will of the American people to make very certain that the world will never so suffer again.\\n\\nAdmittedly, we have been faced with hard choices. It was bitter, for example, not to be able to relieve the heroic and historic defenders of Wake Island. It was bitter for us not to be able to land a million men in a thousand ships in the Philippine Islands.\")]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = retriever.invoke(\"hitler\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Query Retrievers\n",
    "\n",
    "- MQR uses LLM to generate multiple query variations allowing us to focus on key ideas rather than the exact phrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = TextLoader(\"./data/inputs/fdr_speech.txt\").load()\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# embedding_function = FAISS.from_documents(docs, embedding=embeddings)\n",
    "vectore_store = FAISS.load_local(\"./vector_db/course_test/fdr_speech\",\n",
    "                                      embeddings=embeddings,\n",
    "                                      allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = config.groq_key\n",
    "os.environ[\"HTTP_PROXY\"] = config.proxy\n",
    "os.environ[\"HTTPS_PROXY\"] = config.proxy\n",
    "question = \"what did fdr say about Hitler?\"\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectore_store.as_retriever(),\n",
    "                                                  llm = llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/inputs/lincon_speech.txt'}, page_content='A moderate reservation from the interest on the bonds would compensate the United States for the preparation and distribution of the notes and a general supervision of the system, and would lighten the burden of that part of the public debt employed as securities. The public credit, moreover, would be greatly improved and the negotiation of new loans greatly facilitated by the steady market demand for Government bonds which the adoption of the proposed system would create. It is an additional recommendation of the measure, of considerable weight, in my judgment, that it would reconcile as far as possible all existing interests by the opportunity offered to existing institutions to reorganize under the act, substituting only the secured uniform national circulation for the local and various circulation, secured and unsecured, now issued by them.\\n\\nThe receipts into the treasury from all sources, including loans and balance from the preceding year, for the fiscal year ending on the 30th June, 1862, were $583,885,247.06, of which sum $49,056,397.62 were derived from customs; $1,795,331.73 from the direct tax; from public lands, $152,203.77; from miscellaneous sources, $931,787.64; from loans in all forms, $529,692,460.50. The remainder, :$2,257,065.80, was the balance from last year.\\n\\nThe disbursements during the same period were: For Congressional, executive, and judicial purposes, $5,939.009.29; for foreign intercourse, $1,339,710.35; for miscellaneous expenses, including the mints, loans, Post-Office deficiencies, collection of revenue, and other like charges, $14,129,771.50; for expenses under the Interior Department, 985.52; under the War Department, $394,368,407.36; under the Navy Department, $42,674,569.69; for interest on public debt, $13,190,324.45; and for payment of public debt, including reimbursement of temporary loan and redemptions, $96,096,922.09; making an aggregate of $570,841,700.25, and leaving a balance in the Treasury on the 1st day of July, 1862, of $13,043,546.81.'),\n",
       " Document(metadata={'source': './data/inputs/lincon_speech.txt'}, page_content='It should be observed that the sum of $96,096,922.09, expended for reimbursements and redemption of public debt, being included also in the loans made, may be properly deducted both from receipts and expenditures, leaving the actual receipts for the year $487,788,324.97, and the expenditures $474,744,778.16.\\n\\nOther information on the subject of the finances will be found in the report of the Secretary of the Treasury, to whose statements and views I invite your most candid and considerate attention.\\n\\nThe reports of the Secretaries of War and of the Navy are herewith transmitted. These reports, though lengthy, are scarcely more than brief abstracts of the very numerous and extensive transactions and operations conducted through those Departments. Nor could I give a summary of them here upon any principle which would admit of its being much shorter than the reports themselves. I therefore content myself with laying the reports before you and asking your attention to them.'),\n",
       " Document(metadata={'source': './data/inputs/lincon_speech.txt'}, page_content='I ask the attention of Congress to the suggestions of the Postmaster-General in his report respecting the further legislation required, in his opinion, for the benefit of the postal service.\\n\\nThe Secretary of the Interior reports as follows in regard to the public lands:\\n\\nThe public lands have ceased to be a source of revenue. From the 1st July, 1861, to the 30th September, 1862, the entire cash receipts\\nfrom the sale of lands were $137,476.26--a sum much less than the expenses of our land system during the same period. The\\nhomestead law, which will take effect on the 1st of January next, offers such inducements to settlers that sales for cash can not be expected\\nto an extent sufficient to meet the expenses of the General Land Office and the cost of surveying and bringing the land into market.\\nThe discrepancy between the sum here stated as arising from the sales of the public lands and the sum derived from the same source as\\nreported from the Treasury Department arises, as I understand, from the fact that the periods of time, though apparently, were not really\\ncoincident at the beginning point, the Treasury report including a considerable sum now which had previously been reported from the\\nInterior, sufficiently large to greatly overreach the sum derived from the three months now reported upon by the Interior and not by the\\nTreasury.\\n\\nThe Indian tribes upon our frontiers have during the past year manifested a spirit of insubordination, and at several points have engaged in open hostilities against the white settlements in their vicinity. The tribes occupying the Indian country south of Kansas renounced their allegiance to the United States and entered into treaties with the insurgents. Those who remained loyal to the United States were driven from the country. The chief of the Cherokees has visited this city for the purpose of restoring the former relations of the tribe with the United States. He alleges that they were constrained by superior force to enter into treaties with the insurgents, and that the United States neglected to furnish the protection which their treaty stipulations required.'),\n",
       " Document(metadata={'source': './data/inputs/lincon_speech.txt'}, page_content='The reports of the Secretaries of War and of the Navy are herewith transmitted. These reports, though lengthy, are scarcely more than brief abstracts of the very numerous and extensive transactions and operations conducted through those Departments. Nor could I give a summary of them here upon any principle which would admit of its being much shorter than the reports themselves. I therefore content myself with laying the reports before you and asking your attention to them.\\n\\nIt gives me pleasure to report a decided improvement in the financial condition of the Post-Office Department as compared with several preceding years. The receipts for the fiscal year 1861 amounted to $8,349,296.40, which embraced the revenue from all the States of the Union for three quarters of that year. Notwithstanding the cessation of revenue from the so-called seceded States during the last fiscal year, the increase of the correspondence of the loyal States has been sufficient to produce a revenue during the same year of $8,299,820.90, being only $50,000 less than was derived from all the States of the Union during the previous year. The expenditures show a still more favorable result. The amount expended in 1861 was $13,606,759.11. For the last year the amount has been reduced to $11,125,364.13, showing a decrease of about $2,481,000 in the expenditures as compared with the preceding year, and about $3,750,000 as compared with the fiscal year 1860. The deficiency in the Department for the previous year was $4,551,966.98. For the last fiscal year it was reduced to $2,112,814.57. These favorable results are in part owing to the cessation of mail service in the insurrectionary States and in part to a careful review of all expenditures in that Department in the interest of economy. The efficiency of the postal service, it is believed, has also been much improved. The Postmaster-General has also opened a correspondence through the Department of State with foreign governments proposing a convention of postal representatives for the purpose of simplifying the rates of foreign postage and to expedite the foreign mails. This proposition, equally important to our adopted citizens and to the commercial interests of this country, has been favorably entertained and agreed to by all the governments from whom replies have been received.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content=\"We must guard against complacency. We must not underrate the enemy. He is powerful and cunningâ€”and cruel and ruthless. He will stop at nothing that gives him a chance to kill and to destroy. He has trained his people to believe that their highest perfection is achieved by waging war. For many years he has prepared for this very conflict- planning, and plotting, and training, arming, and fighting. We have already tasted defeat. We may suffer further setbacks. We must face the fact of a hard war, a long war, a bloody war, a costly war.\\n\\nWe must, on the other hand, guard against defeatism. That has been one of the chief weapons of Hitler's propaganda machineâ€”used time and again with deadly results. It will not be used successfully on the American people.\\n\\nWe must guard against divisions among ourselves and among all the other United Nations. We must be particularly vigilant against racial discrimination in any of its ugly forms. Hitler will try again to breed mistrust and suspicion between one individual and another, one group and another, one race and another, one Government and another. He will try to use the same technique of falsehood and rumor-mongering with which he divided France from Britain. He is trying to do this with us even now. But he will find a unity of will and purpose against him, which will persevere until the destruction of all his black designs upon the freedom and safety of the people of the world.\\n\\nWe cannot wage this war in a defensive spirit. As our power and our resources are fully mobilized, we shall carry the attack against the enemyâ€”we shall hit him and hit him again wherever and whenever we can reach him.\\n\\nWe must keep him far from our shores, for we intend to bring this battle to him on his own home grounds.\\n\\nAmerican armed forces must be used at any place in all the world where it seems advisable to engage the forces of the enemy. In some cases these operations will be defensive, in order to protect key positions. In other cases, these operations will be offensive, in order to strike at the common enemy, with a view to his complete encirclement and eventual total defeat.\\n\\nAmerican armed forces will operate at many points in the Far East.\\n\\nAmerican armed forces will be on all the oceans- helping to guard the essential communications which are vital to the United Nations.\"),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content='War costs money. So far, we have hardly even begun to pay for it. We have devoted only 15 percent of our national income to national defense. As will appear in my Budget Message tomorrow, [See APP Note.] our war program for the coming fiscal year will cost 56 billion dollars or, in other words, more than half of the estimated annual national income. That means taxes and bonds and bonds and taxes. It means cutting luxuries and other non-essentials. In a word, it means an \"all-out\" war by individual effort and family effort in a united country.\\n\\nOnly this all-out scale of production will hasten the ultimate all-out victory. Speed will count. Lost ground can always be regained- lost time never. Speed will save lives; speed will save this Nation which is in peril; speed will save our freedom and our civilizationâ€”and slowness has never been an American characteristic.\\n\\nAs the United States goes into its full stride, we must always be on guard against misconceptions which will arise, some of them naturally, or which will be planted among us by our enemies.\\n\\nWe must guard against complacency. We must not underrate the enemy. He is powerful and cunningâ€”and cruel and ruthless. He will stop at nothing that gives him a chance to kill and to destroy. He has trained his people to believe that their highest perfection is achieved by waging war. For many years he has prepared for this very conflict- planning, and plotting, and training, arming, and fighting. We have already tasted defeat. We may suffer further setbacks. We must face the fact of a hard war, a long war, a bloody war, a costly war.\\n\\nWe must, on the other hand, guard against defeatism. That has been one of the chief weapons of Hitler\\'s propaganda machineâ€”used time and again with deadly results. It will not be used successfully on the American people.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content='IN FULFILLING my duty to report upon the State of the Union, I am proud to say to you that the spirit of the American people was never higher than it is todayâ€”the Union was never more closely knit togetherâ€”this country was never more deeply determined to face the solemn tasks before it.\\n\\nThe response of the American people has been instantaneous, and it will be sustained until our security is assured.\\n\\nExactly one year ago today I said to this Congress: \"When the dictators. . . are ready to make war upon us, they will not wait for an act of war on our part. . . . Theyâ€”not weâ€”will choose the time and the place and the method of their attack.\"\\n\\nWe now know their choice of the time: a peaceful Sunday morningâ€” December 7, 1941.\\n\\nWe know their choice of the place: an American outpost in the Pacific.\\n\\nWe know their choice of the method: the method of Hitler himself.\\n\\nJapan\\'s scheme of conquest goes back half a century. It was not merely a policy of seeking living room: it was a plan which included the subjugation of all the peoples in the Far East and in the islands of the Pacific, and the domination of that ocean by Japanese military and naval control of the western coasts of North, Central, and South America.\\n\\nThe development of this ambitious conspiracy was marked by the war against China in 1894; the subsequent occupation of Korea; the war against Russia in 1904; the illegal fortification of the mandated Pacific islands following 1920; the seizure of Manchuria in 1931; and the invasion of China in 1937.\\n\\nA similar policy of criminal conquest was adopted by Italy. The Fascists first revealed their imperial designs in Libya and Tripoli. In 1935 they seized Abyssinia. Their goal was the domination of all North Africa, Egypt, parts of France, and the entire Mediterranean world.\\n\\nBut the dreams of empire of the Japanese and Fascist leaders were modest in comparison with the gargantuan aspirations of Hitler and his Nazis. Even before they came to power in 1933, their plans for that conquest had been drawn. Those plans provided for ultimate domination, not of any one section of the world, but of the whole earth and all the oceans on it.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content='We can well say that our men on the fighting fronts have already proved that Americans today are just as rugged and just as tough as any of the heroes whose exploits we celebrate on the Fourth of July.\\n\\nMany people ask, \"When will this war end?\" There is only one answer to that. It will end just as soon as we make it end, by our combined efforts, our combined strength, our combined determination to fight through and work through until the end â€”the end of militarism in Germany and Italy and Japan. Most certainly we shall not settle for less.\\n\\nThat is the spirit in which discussions have been conducted during the visit of the British Prime Minister to Washington. Mr. Churchill and I understand each other, our motives and our purposes. Together, during the past two weeks, we have faced squarely the major military and economic problems of this greatest world war.\\n\\nAll in our Nation have been cheered by Mr. Churchill\\'s visit. We have been deeply stirred by his great message to us. He is welcome in our midst, and we unite in wishing him a safe return to his home.\\n\\nFor we are fighting on the same side with the British people, who fought alone for long, terrible months, and withstood the enemy with fortitude and tenacity and skill.\\n\\nWe are fighting on the same side with the Russian people who have seen the Nazi hordes swarm up to the very gates of Moscow, and who with almost superhuman will and courage have forced the invaders back into retreat.\\n\\nWe are fighting on the same side as the brave people of Chinaâ€”those millions who for four and a half long years have withstood bombs and starvation and have whipped the invaders time and again in spite of the superior Japanese equipment and arms. Yes, we are fighting on the same side as the indomitable Dutch. We are fighting on the same side as all the other Governments in exile, whom Hitler and all his armies and all his Gestapo have not been able to conquer.\\n\\nBut we of the United Nations are not making all this sacrifice of human effort and human lives to return to the kind of world we had after the last world war.\\n\\nWe are fighting today for security, for progress, and for peace, not only for ourselves but for all men, not only for one generation but for all generations. We are fighting to cleanse the world of ancient evils, ancient ills.'),\n",
       " Document(metadata={'source': 'data/inputs/fdr_speech.txt'}, page_content=\"The development of this ambitious conspiracy was marked by the war against China in 1894; the subsequent occupation of Korea; the war against Russia in 1904; the illegal fortification of the mandated Pacific islands following 1920; the seizure of Manchuria in 1931; and the invasion of China in 1937.\\n\\nA similar policy of criminal conquest was adopted by Italy. The Fascists first revealed their imperial designs in Libya and Tripoli. In 1935 they seized Abyssinia. Their goal was the domination of all North Africa, Egypt, parts of France, and the entire Mediterranean world.\\n\\nBut the dreams of empire of the Japanese and Fascist leaders were modest in comparison with the gargantuan aspirations of Hitler and his Nazis. Even before they came to power in 1933, their plans for that conquest had been drawn. Those plans provided for ultimate domination, not of any one section of the world, but of the whole earth and all the oceans on it.\\n\\nWhen Hitler organized his Berlin-Rome-Tokyo alliance, all these plans of conquest became a single plan. Under this, in addition to her own schemes of conquest, Japan's role was obviously to cut off our supply of weapons of war to Britain, and Russia and China- weapons which increasingly were speeding the day of Hitler's doom. The act of Japan at Pearl Harbor was intended to stun usâ€”to terrify us to such an extent that we would divert our industrial and military strength to the Pacific area, or even to our own continental defense.\\n\\nThe plan has failed in its purpose. We have not been stunned. We have not been terrified or confused. This very reassembling of the Seventy-seventh Congress today is proof of that; for the mood of quiet, grim resolution which here prevails bodes ill for those who conspired and collaborated to murder world peace.\\n\\nThat mood is stronger than any mere desire for revenge. It expresses the will of the American people to make very certain that the world will never so suffer again.\\n\\nAdmittedly, we have been faced with hard choices. It was bitter, for example, not to be able to relieve the heroic and historic defenders of Wake Island. It was bitter for us not to be able to land a million men in a thousand ships in the Philippine Islands.\")]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_documents = retriever_from_llm.get_relevant_documents(query=question)\n",
    "unique_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Compression\n",
    "Use LLMs to compress our outputs/display only the relevant outputs\n",
    "\n",
    "Worflow:\n",
    " - Decide on the LLM to use\n",
    " - Use a LLMChanExtractor which uses this LLM\n",
    " - The LLMChainExtractor is used in Contextual Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.load_local(\"./vector_db/course_test/fdr_speech\",\n",
    "                                      embeddings=embeddings,\n",
    "                                      allow_dangerous_deserialization=True)\n",
    "compressor = LLMChainExtractor.from_llm(llm=llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor = compressor,\n",
    "                                                       base_retriever = vector_db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_doc = compression_retriever.invoke(\"What is the impact of war?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the extracted relevant parts:\n",
      "\n",
      "War costs money. So far, we have hardly even begun to pay for it. We have devoted only 15 percent of our national income to national defense. As will appear in my Budget Message tomorrow, our war program for the coming fiscal year will cost 56 billion dollars or, in other words, more than half of the estimated annual national income. That means taxes and bonds and bonds and taxes. It means cutting luxuries and other non-essentials. In a word, it means an \"all-out\" war by individual effort and family effort in a united country.\n",
      "\n",
      "This part of the context is relevant to the question \"What is the impact of war?\" as it discusses the financial costs of war and the impact it has on the country, including the need for increased taxes and reduced luxuries.\n",
      "\n",
      "data/inputs/fdr_speech.txt\n"
     ]
    }
   ],
   "source": [
    "print(compressed_doc[0].page_content, end=\"\\n\")\n",
    "print()\n",
    "print(compressed_doc[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Connections Exercise\n",
    "\n",
    "Create an LLM bot which can:\n",
    "- Takes questions about the US Constitution and returns the most relevant part on the constitution as the answer.\n",
    "- It may not directly answer the question.\n",
    "- Return the compressed version of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def create_vector_db():\n",
    "    \n",
    "    # Load text\n",
    "    docs = TextLoader(\"data/langchain-course-main/01-Data-Connections/some_data/US_Constitution.txt\").load()\n",
    "    # docs = PyPDFLoader(\"./data/inputs/constitution.pdf\").load()\n",
    "    \n",
    "    # Chunk the text using text_splitter\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "    chunked_doc = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Convert text to embeddings/create vector db\n",
    "    library = FAISS.from_documents(chunked_doc, embedding=embeddings)\n",
    "\n",
    "    # Save Embeddings\n",
    "    library.save_local(\"vector_db/law_bot\")\n",
    "\n",
    "    pass\n",
    "\n",
    "def law_bot(question):\n",
    "\n",
    "    # Load vector_db\n",
    "    vector_db = FAISS.load_local(\"vector_db/law_bot\",\n",
    "                                 embeddings=embeddings,\n",
    "                                 allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Convert the vector db to a retriever\n",
    "    llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
    "    # retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vector_db.as_retriever(),\n",
    "    #                                                   llm = llm)\n",
    "    retriever = vector_db.as_retriever()\n",
    "    # Initialize Compressor\n",
    "    compressor = LLMChainExtractor.from_llm(llm=llm)\n",
    "\n",
    "    # Pass the compressor and the retiever to the ContextualCompressor to get the compressed answer\n",
    "    compressed_retriever = ContextualCompressionRetriever(base_compressor = compressor,\n",
    "                                                          base_retriever = retriever)\n",
    "    \n",
    "    # Invoke the retriever\n",
    "    ans = compressed_retriever.invoke(question)\n",
    "\n",
    "    return ans\n",
    "\n",
    "create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/langchain-course-main/01-Data-Connections/some_data/US_Constitution.txt'}, page_content='Here are the extracted relevant parts:\\n\\nThe Electors shall meet in their respective states and vote by ballot for President and Vice-President, one of whom, at least, shall not be an inhabitant of the same state with themselves...\\n\\nThe person having the greatest number of votes for President, shall be the President, if such number be a majority of the whole number of Electors appointed...\\n\\nThe person having the greatest number of votes as Vice-President, shall be the Vice-President, if such number be a majority of the whole number of Electors appointed...\\n\\nNote that these parts are directly related to the 12th Amendment, which deals with the process of electing the President and Vice-President.'),\n",
       " Document(metadata={'source': 'data/langchain-course-main/01-Data-Connections/some_data/US_Constitution.txt'}, page_content='Here are the extracted relevant parts:\\n\\nSection 1\\nThe District constituting the seat of Government of the United States shall appoint in such manner as Congress may direct:\\n\\nA number of electors of President and Vice President equal to the whole number of Senators and Representatives in Congress to which the District would be entitled if it were a State, but in no event more than the least populous State; they shall be in addition to those appointed by the States, but they shall be considered, for the purposes of the election of President and Vice President, to be electors appointed by a State; and they shall meet in the District and perform such duties as provided by the twelfth article of amendment.\\n\\nThis is the relevant part that mentions the 12th Amendment.')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"12th Amendment?\"\n",
    "ans = law_bot(question)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
